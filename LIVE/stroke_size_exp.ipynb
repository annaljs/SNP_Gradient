{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anna/anaconda3/envs/live/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import torch\n",
    "import json\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device('cuda') if use_gpu else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate stroke size ratio and store json record\n",
    "test_direct = \"data/single_strokes/single_strokes_990/sunflowers_rendered_single_stroke_0\"\n",
    "loss_list = []\n",
    "\n",
    "for i in range(1,991):\n",
    "    num = str(i)\n",
    "    if len(num) == 1 :\n",
    "        num = '00' + num\n",
    "    if len(num) == 2:\n",
    "        num = '0' + num\n",
    "    stroke_filname = test_direct + num + \".png\"\n",
    "    gt = np.array(PIL.Image.open(stroke_filname))\n",
    "\n",
    "    if gt.shape[2] == 4:\n",
    "        #print(\"Input image includes alpha channel, simply dropout alpha channel.\")\n",
    "        gt = gt[:, :, :3]\n",
    "\n",
    "    gt = (gt/255).astype(np.float32)\n",
    "    gt = torch.FloatTensor(gt).permute(2, 0, 1)[None].to(device)\n",
    "    gt = gt.detach().cpu().numpy()\n",
    "\n",
    "    h, w = gt.shape[2:]\n",
    "    para_bg = torch.tensor([1., 1., 1.], requires_grad=False, device=device)\n",
    "    pred = para_bg.view(1, -1, 1, 1).repeat(1, 1, h, w)\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "\n",
    "    map = ((pred[0] - gt[0])**2).sum(0)\n",
    "    pixel_num = w*h\n",
    "    zero_count = len(map[map==0.0])\n",
    "    ratio = zero_count / pixel_num\n",
    "    loss_list.append(\"{:.4f}\".format(ratio))\n",
    "\n",
    "results = {\n",
    "    'loss': loss_list,\n",
    "}\n",
    "\n",
    "print(json.dumps(results,indent=4))\n",
    "\n",
    "with open(f'{\"experiment/evaluation\"}/stroke_size.json', 'w') as writer:\n",
    "    json.dump(results, writer, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate different path numbers stroke with GT and store json record\n",
    "gt_direct = \"data/single_strokes/single_strokes_495/sunflowers_rendered_single_stroke_\"\n",
    "test_direct = \"log/test/sunflowers_rendered_single_stroke_\"\n",
    "record = {}\n",
    "\n",
    "for i in range(1, 496) :\n",
    "    num = str(i)\n",
    "    if len(num) == 1 :\n",
    "        num = '000' + num\n",
    "    if len(num) == 2:\n",
    "        num = '00' + num\n",
    "    if len(num) == 3:\n",
    "        num = '0' + num\n",
    "\n",
    "    gt_filname = gt_direct +  num + \".png\"\n",
    "    gt = np.array(PIL.Image.open(gt_filname))\n",
    "\n",
    "    if gt.shape[2] == 4:\n",
    "        #print(\"Input image includes alpha channel, simply dropout alpha channel.\")\n",
    "        gt = gt[:, :, :3]\n",
    "\n",
    "    gt = (gt/255).astype(np.float32)\n",
    "    gt = torch.FloatTensor(gt).permute(2, 0, 1)[None].to(device)\n",
    "\n",
    "    loss_list = []\n",
    "\n",
    "    for j in range(1, 11) :\n",
    "        \n",
    "        path_num = str(j)\n",
    "        stroke_filname = test_direct + num + \"/demo-png/\" + path_num + \".png\"\n",
    "\n",
    "        pred = np.array(PIL.Image.open(stroke_filname))\n",
    "\n",
    "        if pred.shape[2] == 4:\n",
    "            #print(\"Input image includes alpha channel, simply dropout alpha channel.\")\n",
    "            pred = pred[:, :, :3]\n",
    "\n",
    "        pred = (pred/255).astype(np.float32)\n",
    "        pred = torch.FloatTensor(pred).permute(2, 0, 1)[None].to(device)\n",
    "        \n",
    "        loss = ((pred-gt)**2)\n",
    "        loss = loss.sum(1).mean().item()\n",
    "        #print(loss)\n",
    "        loss_list.append(float(loss))\n",
    "    record[i] = loss_list\n",
    "\n",
    "results = {\n",
    "    'loss': record,\n",
    "}\n",
    "\n",
    "#print(json.dumps(results,indent=4))\n",
    "\n",
    "with open(f'{\"experiment/evaluation\"}/results.json', 'w') as writer:\n",
    "    json.dump(results, writer, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#算全部筆畫的tolerence mse path num\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "f = open('./experiment/evaluation/stroke_all_gt_mse.json')\n",
    "data = json.load(f)\n",
    "\n",
    "data = data['loss']\n",
    "list = []\n",
    "for item in data :\n",
    "    print(item)\n",
    "    mse_data = np.array(data[item])\n",
    "    mse_data = mse_data.astype(np.float32)\n",
    "\n",
    "    # Set the initial MSE value and tolerance level\n",
    "    initial_mse = (mse_data[0] - mse_data[1])\n",
    "    tolerance = 0.1 * initial_mse  # Set the tolerance level to 1% of the initial MSE value\n",
    "\n",
    "    # Check for convergence\n",
    "    converged = False\n",
    "    for i in range(1, len(mse_data)):\n",
    "        if -1*(mse_data[i] - mse_data[i-1]) < tolerance:\n",
    "            list.append(i)\n",
    "            print(f'Converged after {i} epochs')\n",
    "            print(mse_data[i])\n",
    "            converged = True\n",
    "            break\n",
    "\n",
    "    if not converged:\n",
    "        list.append(len(mse_data))\n",
    "        print('Did not converge')\n",
    "\n",
    "results = {\n",
    "    'stroke num': list,\n",
    "}\n",
    "\n",
    "#print(json.dumps(results,indent=4))\n",
    "\n",
    "with open(f'{\"experiment/evaluation\"}/stroke_results.json', 'w') as writer:\n",
    "    json.dump(results, writer, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#算單一筆畫的tolerence mse path num\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "f = open('./experiment/evaluation/stroke42_gt_mse.json')\n",
    "data = json.load(f)\n",
    "mse_data = np.array(data['loss'])\n",
    "mse_data = mse_data.astype(np.float32)\n",
    "\n",
    "# Set the initial MSE value and tolerance level\n",
    "initial_mse = mse_data[0] - mse_data[1]\n",
    "tolerance = 0.5 * initial_mse  # Set the tolerance level to 1% of the initial MSE value\n",
    "\n",
    "# Check for convergence\n",
    "converged = False\n",
    "for i in range(1, len(mse_data)):\n",
    "    if abs(mse_data[i] - mse_data[i-1]) < tolerance:\n",
    "        list.append(i)\n",
    "        print(f'Converged after {i} epochs')\n",
    "        converged = True\n",
    "        break\n",
    "\n",
    "if not converged:\n",
    "    print('Did not converge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4 3\n"
     ]
    }
   ],
   "source": [
    "#根據tolerence stroke num path 合成結果\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "svg = ET.Element('svg', width='512', height='512')\n",
    "file_direct = \"log/path10/sunflowers_rendered_single_stroke_\"\n",
    "\n",
    "data = json.load(open('./experiment/evaluation/stroke_results.json'))\n",
    "stroke_num_data = np.array(data['stroke num'])\n",
    "\n",
    "label = json.load( open('./experiment/evaluation/stroke_label.json') )\n",
    "stroke_label_data = np.array(label['label'])\n",
    "\n",
    "label_0 = 0\n",
    "label_1 = 0 \n",
    "label_2 = 0\n",
    "# label_3 = 0 \n",
    "# label_4 = 0\n",
    "label_0_size = 0\n",
    "label_1_size = 0 \n",
    "label_2_size = 0\n",
    "# label_3_size = 0 \n",
    "# label_4_size = 0\n",
    "\n",
    "for i in range(0,(stroke_num_data).size-1):\n",
    "    if stroke_label_data[i] == 0 :\n",
    "        label_0 += stroke_num_data[i]\n",
    "        label_0_size += 1\n",
    "    if stroke_label_data[i] == 1 :\n",
    "        label_1 += stroke_num_data[i]\n",
    "        label_1_size += 1\n",
    "    if stroke_label_data[i] == 2 :\n",
    "        label_2 += stroke_num_data[i]\n",
    "        label_2_size += 1\n",
    "    # if stroke_label_data[i] == 3 :\n",
    "    #     label_3 += stroke_num_data[i]\n",
    "    #     label_3_size += 1\n",
    "    # if stroke_label_data[i] == 4 :\n",
    "    #     label_4 += stroke_num_data[i]\n",
    "    #     label_4_size += 1\n",
    "label_0_averrage = round(label_0 / label_0_size)\n",
    "label_1_averrage = round(label_1 / label_1_size)\n",
    "label_2_averrage = round(label_2 / label_2_size)\n",
    "# label_3_averrage = round(label_3 / label_3_size)\n",
    "# label_4_averrage = round(label_4 / label_4_size)\n",
    "print(label_0_averrage,label_1_averrage,label_2_averrage)\n",
    "former_animateID = \"a0001\"\n",
    "for i in range(0, 495) :\n",
    "    num = str(i+1)\n",
    "    if len(num) == 1 :\n",
    "        num = '000' + num\n",
    "    if len(num) == 2:\n",
    "        num = '00' + num\n",
    "    if len(num) == 3:\n",
    "        num = '0' + num\n",
    "    pathID = \"stroke_\" + num\n",
    "    animateID = \"a\" + num\n",
    "    path_num = str(4) #str(stroke_num_data[i]) # different path num\n",
    "    # if stroke_label_data[i] == 0 :\n",
    "    #     path_num = str(label_0_averrage)\n",
    "    # if stroke_label_data[i] == 1 :\n",
    "    #     path_num = str(label_1_averrage)\n",
    "    # if stroke_label_data[i] == 2 :\n",
    "    #     path_num = str(label_2_averrage)\n",
    "    # if stroke_label_data[i] == 3 :\n",
    "    #     path_num = str(label_3_averrage)\n",
    "    # if stroke_label_data[i] == 4 :\n",
    "    #     path_num = str(label_4_averrage)       \n",
    "    stroke_filname = file_direct + num + \"/output-svg/\" + path_num + \".svg\"\n",
    "    #print(stroke_filname)\n",
    "    group = ET.Element('g')\n",
    "    group.set('id', pathID)\n",
    "    tree1 = ET.parse(stroke_filname)\n",
    "    root1 = tree1.getroot()\n",
    "    for path in root1.iter('{http://www.w3.org/2000/svg}path'):\n",
    "        fill_attrib = path.attrib.get('fill')\n",
    "        rgb_values = fill_attrib.split(',')\n",
    "        r = int(rgb_values[0][4:])\n",
    "        g = int(rgb_values[1])\n",
    "        b = int(rgb_values[2][:-1])\n",
    "        brightness = (r + g + b) / 3\n",
    "        if brightness < 240:\n",
    "            group.append(path)\n",
    "\n",
    "    animate1 = ET.Element('animate', {\n",
    "        'attributeType': 'XML',\n",
    "        'attributeName': 'opacity',\n",
    "        'from': '0',\n",
    "        'to': '0',\n",
    "        'begin': '0s',\n",
    "        'fill': 'freeze'\n",
    "    })\n",
    "    group.append(animate1)\n",
    "    animate2 = ET.Element('animate', {\n",
    "        'id': animateID,\n",
    "        'attributeType': 'XML',\n",
    "        'attributeName': 'opacity',\n",
    "        'from': '0',\n",
    "        'to': '1',\n",
    "        'dur': '50ms',\n",
    "        'begin': former_animateID + '.end+50ms',\n",
    "        'fill': 'freeze'\n",
    "    })\n",
    "    group.append(animate2)\n",
    "    svg.append(group)\n",
    "    former_animateID = animateID\n",
    "tree = ET.ElementTree(svg)   \n",
    "tree.write('output/test/merged_4.svg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
